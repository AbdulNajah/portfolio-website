{
  "hash": "de3ac9f841cd506d6bb6ac05b9450751",
  "result": {
    "markdown": "---\ntitle: \"Satellite Image Clasification using Machine Learning\"\nauthor: \"Najah\"\ndate: \"2023-06-23\"\ndescription: \"Estimating the urbanisation in Delhi Using Google Earth Engine and Machine Learning\"\nfilters:\n   - lightbox\nlightbox: \n  match: auto\ncategories: [GEE, Remote Sensing ,Machine Learning]\nexecute: \n  eval: false\nformat:\n  html:\n    theme:\n      light: cosmo\n      dark: [cosmo, theme_dark_custom.scss]\n    code-link: true\n    code-fold: show\n    code-tools: true\n    code-block-bg: \"lightblue\"\n---\n\n## Introduction:\n\nIn this post, I am excited to share a project I completed as part of my machine learning course at Ashoka University. The objective was to leverage machine learning to understand the extent of urbanisation in the city of Delhi. Using the concept of built-up areas as a proxy for urban areas, I applied Random Forest machine learning algorithm to estimate the built-up area in Delhi.\n\n## Methodology:\n\n1.  Obtaining Delhi Boundary Geometry:\n\n    To initiate the project, I obtained the precise boundary geometry of Delhi using the FAO/GAUL/2015/level2 dataset. This enabled me to focus specifically on the area of interest and streamline the analysis.\n\n2.  Filtering Sentinel-2 Imagery:\n\n    Next, I accessed the Sentinel-2 satellite imagery from the COPERNICUS/S2_SR image collection. To ensure high-quality data, I filtered the imagery based on a cloud cover percentage of less than 30% and a date range of January 1, 2019, to December 31, 2019. Additionally, I restricted the imagery to be within the bounds of Delhi, using the previously acquired boundary geometry. Subsequently, I selected the relevant spectral bands (B4, B3, B2) for the analysis.\n\n```js\n// Code snippet 1: Filtering Sentinel-2 imagery\nvar sentinel2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n  .filterBounds(delhiBoundaryGeometry)\n  .filterDate(\"2019-01-01\", \"2019-12-31\")\n  .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 30))\n  .select([\"B4\", \"B3\", \"B2\"]);\n\n```\n\n3.  Creating the Composite Image:\n\n    Afterwards, I created a composite image by taking the median of the filtered images and clipped it to the boundary of Delhi. The resulting composite image provided a comprehensive representation of the land cover in the region.\n\n    I then created a composite image by taking the median of the filtered images and clipped it to the boundary of Delhi. This composite image provided a comprehensive representation of the land cover in the region.\n\n\n```{js}\n// Code snippet 2: Creating the composite image\nvar composite = sentinel2.median().clip(delhiBoundaryGeometry);\n\n```\n\n\n4.  Visualising the Composite Image\n\n    To visualise the composite image, I applied a colour visualisation scheme using the red, green, and blue bands. This enhanced the image and provided valuable insights into the distribution of different land cover types within Delhi.\n\n\n```{js}\n\n// Code Snippet: Visualising the Composite Image\n\n// Apply colour visualization parameters\nvar visualizationParams = {\n  bands: ['B4', 'B3', 'B2'],\n  min: 0.0,\n  max: 3000\n};\n\n// Display the composite image\n\nMap.addLayer(compositeImage, visualizationParams, 'Composite Image');\n\n```\n\n\n**Composite Image**\n\n![Composite image of Delhi](delhi_before.png){fig-alt=\"Composite Image\" fig-align=\"left\"}\n\n4.  Land Cover Classification Training Data: I manually annotated approximately 500 urban and non-urban points across Delhi to create the training data. I uploaded them to GEE assets as feature collection. I utilised that feature collection consisting of urban and non-urban points. Merging these collections provided a comprehensive set of training data for the classification process.\n\n\n```{js}\n// Code Snippet: Utilising the Feature Collection for Classification\n// Load the feature collections of urban and non-urban points\nvar urbanPoints = ee.FeatureCollection(\"projects/ee-najah/assets/urban_points\");\nvar nonUrbanPoints = ee.FeatureCollection(\"projects/ee-najah/assets/non_urban_points\");\n\n// Merge the urban and non-urban points collections\nvar trainingData = urbanPoints.merge(nonUrbanPoints);\n```\n\n\n5.  Overlaying Training Points and Extracting Training Data:\n\n    Next, I overlayed the training points on the composite image to extract the necessary training data. This involved sampling regions within a specified scale of 10 units using the \"sampleRegions\" function, which resulted in the training data consisting of land cover labels associated with each region.\n\n\n```{js}\n// Code Snippet: Overlaying Training Points on the Composite Image\n// Sample regions within a specified scale of 10 units\nvar trainingData = compositeImage.sampleRegions({\n  collection: trainingData,\n  scale: 10,\n  properties: ['land_cover'],\n});\n```\n\n\n6.  Splitting the Dataset: To evaluate the accuracy of the classification model, I split the dataset into training and testing sets. The training set was used to train the machine learning model, while the testing set was utilized to assess the model's performance.\n\n\n```{js}\n\n\n// Code snippet 5: Splitting the dataset into training and testing sets\nvar split = 0.8; // 80% for training, 20% for testing\nvar training = trainingData.randomColumn('split').filter(ee.Filter.lt('split', split));\nvar testing = trainingData.randomColumn('split').filter(ee.Filter.gte('split', split));\n\n```\n\n\n7.  Training the Random Forest Classifier:\n\n    Using the training data, I trained a random forest classifier with the \"smileRandomForest\" algorithm provided by Earth Engine. The classifier was trained with 50 trees, and the land cover property was used as the target class. The input properties for classification were derived from the band names of the composite image.\n\n\n```{js}\n// Code Snippet: Training the Random Forest Classifier\n\n// Train a random forest classifier with 500 trees\nvar classifier = ee.Classifier.smileRandomForest(500)\n  .train({\n    features: training,\n    classProperty: 'land_cover',\n    inputProperties: ['B4', 'B3', 'B2']\n  });\n```\n\n\n7.  Applying the Classifier to Generate Land Cover Classification Map\n\n    Finally, I applied the trained classifier to the composite image to generate a land cover classification map. The classified image assigned distinct colours to different land cover classes, with the colour palette including shades of grey, brown, blue, and green. This visualisation provided a clear understanding of the land cover distribution in Delhi during the year 2019.\n\n\n```{js}\n// Code Snippet: Applying the Classifier to Generate Land Cover Classification Map\n\n// Apply the trained classifier to the composite image\nvar classified = compositeImage.classify(classifier);\n\n// Display the land cover classification map\nMap.addLayer(classified, { palette: ['gray', 'brown', 'blue', 'green'] }, 'Land Cover Classification');\n```\n\n\n**Land Classification Map**\n\n![Image: Land cover classification map of Delhi](delhi_after.png){fig-alt=\"Delhi classification result\" fig-align=\"left\"}\n\n8.  Accuracy Assessment: To assess the accuracy of the classification model, I calculated the confusion matrix using the testing dataset. The confusion matrix provided insights into the model's performance, including metrics such as overall accuracy, producer's accuracy, and user's accuracy.\n\n\n```{js}\n// Code snippet 7: Calculating the confusion matrix for accuracy assessment\nvar testAccuracy = testing\n    .classify(classifier)\n    .errorMatrix('class', 'classification');\n\nprint('Confusion Matrix:', testAccuracy);\nprint('Overall Accuracy:', testAccuracy.accuracy());\n\n```\n\n\n9.  Calculating Urban Area Percentage:\n\n    To understand the extent of urbanization, we calculated the area covered by the urban class within Delhi. We also calculated the total area of Delhi to determine the percentage of urban area.\n\n\n```{js}\n\n// New Code Snippet: Calculating urban area percentage\n\n// Calculating area of urban class\nvar urban = classified.select('classification').eq(1);\n\n// Calculate the pixel area in square kilometer for urban\nvar area_urban = urban.multiply(ee.Image.pixelArea()).divide(1000 * 1000);\n\n// Reducing the statistics for urban area in Delhi\nvar stat_urban = area_urban.reduceRegion({\n  reducer: ee.Reducer.sum(),\n  geometry: delhi,\n  scale: 100,\n  maxPixels: 1e10\n});\n\n// Get the sum of pixel values representing urban area\nvar area_urban_sum = ee.Number(stat_urban.get('classification'));\n\n// Calculate the pixel area in square kilometer for Delhi\nvar area_delhi = ee.Image.pixelArea().clip(delhi).divide(1000 * 1000);\n\n// Reducing the statistics for Delhi\nvar stat_delhi = area_delhi.reduceRegion({\n  reducer: ee.Reducer.sum(),\n  geometry: delhi,\n  scale: 100,\n  maxPixels: 1e10\n});\n\n// Get the sum of pixel values representing Delhi area\nvar area_delhi_sum = ee.Number(stat_delhi.get('area'));\n\n// Calculate the percentage of urban area\nvar percentage_urban_area = area_urban_sum.divide(area_delhi_sum).multiply(100);\n\n// Print the urban area in square kilometers\nprint('Urban Area (in sq.km):', area_urban_sum);\n\n// Print the total area of Delhi\nprint('Delhi Area (in sq.km):', area_delhi_sum);\n\n// Print the percentage of urban area\nprint('Percentage of urban area:', percentage_urban_area);\n\n```\n\n\n10. Exporting the Results:\n\nLastly, I exported the classified image and the confusion matrix results to Google Drive for further analysis and sharing with collaborators.\n\n\n```{js}\n\n// Code snippet 8: Exporting the classified image and confusion matrix to Google Drive\nExport.image.toDrive({\n  image: classified,\n  description: 'classified_image',\n  folder: 'GEE_Classification_Results',\n  scale: 10,\n  region: delhi\n});\n\nExport.table.toDrive({\n  collection: testAccuracy,\n  description: 'confusion_matrix',\n  folder: 'GEE_Classification_Results',\n  fileFormat: 'CSV'\n});\n\n```\n\n\n## Results and Conclusion\n\n-   The land cover classification analysis using the basic Random Forest model achieved an overall accuracy of 87%, indicating the model's effectiveness in accurately classifying land cover types in Delhi based on satellite imagery data.\n\n-   To further improve the classification results, additional enhancements can be implemented, such as incorporating spectral indices like NDVI (Normalised Difference Vegetation Index) or NDBI (Normalised Difference Built-up Index) to provide additional information for distinguishing different land cover types.\n\n-   Hyperparameter optimisation can be performed to fine-tune the Random Forest model, adjusting parameters such as the number of trees, tree depth, and feature subsampling, with the potential to achieve higher accuracy.\n\n-   This project primarily focused on land cover classification in Delhi, but there is potential for extending the analysis to other Indian cities. Analysing the model's performance in different urban environments would provide valuable insights into its generalisability and scalability.\n\n-   The classification results suggest that approximately 78% of Delhi can be classified as urban, highlighting the significant urbanisation within the city.\n\n-   By tracking the historical growth of urban areas in Delhi using satellite imagery, it is possible to gain a deeper understanding of urban expansion patterns over time.\n\n[**Link to Google Earth Engine script**](www.example.com)\n\n[**Link to original research paper**](www.example.com)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}