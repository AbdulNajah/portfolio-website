[
  {
    "objectID": "posts/compare-spectra/index.html",
    "href": "posts/compare-spectra/index.html",
    "title": "Compare Spectra App",
    "section": "",
    "text": "Introducing the compare-spectra app!\nHello everyone!\nI’m excited to share a new Earth Engine app that I’ve developed, designed to simplify spectral analysis for remote sensing projects. It’s a practical tool that I believe can make a difference in the way we approach and interpret spectral data.\nThe inspiration for this app came from a conversation I had with my friend Lucy. They needed to compare the spectra of teak and pine for a project. It got me thinking about the challenges researchers and analysts face when working with spectral data. The process can often be time-consuming, complex, and require expensive software.\nWith this in mind, I set out to create an Earth Engine app that would alleviate these difficulties. The goal was to make spectral analysis more accessible and user-friendly, enabling anyone to explore and compare spectra without the need for extensive coding or expensive tools.\nHere’s a quick overview of what my Earth Engine app offers:\n1. Select Your Study Area: Start by choosing the area you want to study on the map. It’s as simple as clicking on the desired location. Define the extent and select the satellite product that best suits your research objectives.\n2. Draw Regions of Interest (ROIs): The app allows you to draw ROIs directly on the map. Whether you’re comparing different objects or classes, you can easily add and define your ROIs. It’s a flexible and intuitive process that doesn’t require advanced scripting knowledge.\n3. Generate Comparative Line Charts: Once you’ve defined your ROIs, click the “Generate” button, and the app will generate visually appealing line charts that compare the spectra of the selected areas. These charts provide valuable insights and help identify variations and patterns in the data.\n4. Customize and Share: To further enhance the utility of the app, you have the option to download the generated charts as images or export the spectral data as a CSV file. This allows you to customize the visuals or integrate the data into other tools or publications.\nThis is not intended to be a groundbreaking solution, but rather a helpful resource for those working in remote sensing. It’s been designed to streamline your workflow and provide a more user-friendly experience.\nCheck out the app here. Take it for a spin, experiment with different ROIs, and see how it can assist you in your spectral analysis endeavors. Your feedback and suggestions are highly appreciated as I continue to improve and refine this app.\nHere’s the demo on how to use the app :"
  },
  {
    "objectID": "posts/cpr-pol-connect/index.html",
    "href": "posts/cpr-pol-connect/index.html",
    "title": "Data Science works at CPR",
    "section": "",
    "text": "In this blog you will find some of the data science work that I was involved in as an analyst at the Centre for Policy Research, New Delhi\nVisit the showcase website here"
  },
  {
    "objectID": "posts/delhi_lulc/index.html",
    "href": "posts/delhi_lulc/index.html",
    "title": "Satellite Image Clasification using Machine Learning",
    "section": "",
    "text": "In this post, I am sharing a project I completed as part of my machine learning course at Ashoka University. The objective was to leverage machine learning to understand the extent of urbanisation in the city of Delhi. Using the concept of built-up areas as a proxy for urban areas, I applied Random Forest machine learning algorithm to estimate the built-up area in Delhi."
  },
  {
    "objectID": "posts/delhi_lulc/index.html#introduction",
    "href": "posts/delhi_lulc/index.html#introduction",
    "title": "Satellite Image Clasification using Machine Learning",
    "section": "",
    "text": "In this post, I am sharing a project I completed as part of my machine learning course at Ashoka University. The objective was to leverage machine learning to understand the extent of urbanisation in the city of Delhi. Using the concept of built-up areas as a proxy for urban areas, I applied Random Forest machine learning algorithm to estimate the built-up area in Delhi."
  },
  {
    "objectID": "posts/delhi_lulc/index.html#methodology",
    "href": "posts/delhi_lulc/index.html#methodology",
    "title": "Satellite Image Clasification using Machine Learning",
    "section": "Methodology:",
    "text": "Methodology:\n\nObtaining Delhi Boundary Geometry:\nTo initiate the project, I obtained the precise boundary geometry of Delhi using the FAO/GAUL/2015/level2 dataset. This enabled me to focus specifically on the area of interest and streamline the analysis.\n\n\nFiltering Sentinel-2 Imagery:\nNext, I accessed the Sentinel-2 satellite imagery from the COPERNICUS/S2_SR image collection. To ensure high-quality data, I filtered the imagery based on a cloud cover percentage of less than 30% and a date range of January 1, 2019, to December 31, 2019. Additionally, I restricted the imagery to be within the bounds of Delhi, using the previously acquired boundary geometry. Subsequently, I selected the relevant spectral bands (B4, B3, B2) for the analysis.\n// Code snippet 1: Filtering Sentinel-2 imagery\nvar sentinel2 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n  .filterBounds(delhiBoundaryGeometry)\n  .filterDate(\"2019-01-01\", \"2019-12-31\")\n  .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 30))\n  .select([\"B4\", \"B3\", \"B2\"]);\n\n\nCreating the Composite Image:\nAfterwards, I created a composite image by taking the median of the filtered images and clipped it to the boundary of Delhi. The resulting composite image provided a comprehensive representation of the land cover in the region.\nI then created a composite image by taking the median of the filtered images and clipped it to the boundary of Delhi. This composite image provided a comprehensive representation of the land cover in the region.\n// Code snippet 2: Creating the composite image\nvar composite = sentinel2.median().clip(delhiBoundaryGeometry);\n\n\nVisualising the Composite Image\nTo visualise the composite image, I applied a colour visualisation scheme using the red, green, and blue bands. This enhanced the image and provided valuable insights into the distribution of different land cover types within Delhi.\n\n// Code Snippet: Visualising the Composite Image\n\n// Apply colour visualization parameters\nvar visualizationParams = {\n  bands: ['B4', 'B3', 'B2'],\n  min: 0.0,\n  max: 3000\n};\n\n// Display the composite image\n\nMap.addLayer(compositeImage, visualizationParams, 'Composite Image');\nComposite Image\n\n\n\nComposite image of Delhi\n\n\n\n\nLand Cover Classification Training Data:\nI manually annotated approximately 500 urban and non-urban points across Delhi to create the training data. I uploaded them to GEE assets as feature collection. I utilised that feature collection consisting of urban and non-urban points. Merging these collections provided a comprehensive set of training data for the classification process.\n// Code Snippet: Utilising the Feature Collection for Classification\n// Load the feature collections of urban and non-urban points\nvar urbanPoints = ee.FeatureCollection(\"projects/ee-najah/assets/urban_points\");\nvar nonUrbanPoints = ee.FeatureCollection(\"projects/ee-najah/assets/non_urban_points\");\n\n// Merge the urban and non-urban points collections\nvar trainingData = urbanPoints.merge(nonUrbanPoints);\n\n\nOverlaying Training Points and Extracting Training Data:\nNext, I overlayed the training points on the composite image to extract the necessary training data. This involved sampling regions within a specified scale of 10 units using the “sampleRegions” function, which resulted in the training data consisting of land cover labels associated with each region.\n// Code Snippet: Overlaying Training Points on the Composite Image\n// Sample regions within a specified scale of 10 units\nvar trainingData = compositeImage.sampleRegions({\n  collection: trainingData,\n  scale: 10,\n  properties: ['land_cover'],\n});\n\n\nSplitting the Dataset:\nTo evaluate the accuracy of the classification model, I split the dataset into training and testing sets. The training set was used to train the machine learning model, while the testing set was utilized to assess the model’s performance.\n\n\n// Code snippet 5: Splitting the dataset into training and testing sets\nvar split = 0.8; // 80% for training, 20% for testing\nvar training = trainingData.randomColumn('split').filter(ee.Filter.lt('split', split));\nvar testing = trainingData.randomColumn('split').filter(ee.Filter.gte('split', split));\n\n\nTraining the Random Forest Classifier:\nUsing the training data, I trained a random forest classifier with the “smileRandomForest” algorithm provided by Earth Engine. The classifier was trained with 50 trees, and the land cover property was used as the target class. The input properties for classification were derived from the band names of the composite image.\n// Code Snippet: Training the Random Forest Classifier\n\n// Train a random forest classifier with 500 trees\nvar classifier = ee.Classifier.smileRandomForest(500)\n  .train({\n    features: training,\n    classProperty: 'land_cover',\n    inputProperties: ['B4', 'B3', 'B2']\n  });\n\n\nApplying the Classifier to Generate Land Cover Classification Map\nFinally, I applied the trained classifier to the composite image to generate a land cover classification map. The classified image assigned distinct colours to different land cover classes, with the colour palette including shades of grey, brown, blue, and green. This visualisation provided a clear understanding of the land cover distribution in Delhi during the year 2019.\n// Code Snippet: Applying the Classifier to Generate Land Cover Classification Map\n\n// Apply the trained classifier to the composite image\nvar classified = compositeImage.classify(classifier);\n\n// Display the land cover classification map\nMap.addLayer(classified, { palette: ['gray', 'red'] }, 'Land Cover Classification');\nLand Classification Map\n\n\n\nImage: Land cover classification map of Delhi\n\n\n\n\nAccuracy Assessment:\nTo assess the accuracy of the classification model, I calculated the confusion matrix using the testing dataset. The confusion matrix provided insights into the model’s performance, including metrics such as overall accuracy, producer’s accuracy, and user’s accuracy.\n// Code snippet 7: Calculating the confusion matrix for accuracy assessment\nvar testAccuracy = testing\n    .classify(classifier)\n    .errorMatrix('class', 'classification');\n\nprint('Confusion Matrix:', testAccuracy);\nprint('Overall Accuracy:', testAccuracy.accuracy());\n\n\nCalculating Urban Area Percentage:\nTo understand the extent of urbanization, we calculated the area covered by the urban class within Delhi. We also calculated the total area of Delhi to determine the percentage of urban area.\n\n// New Code Snippet: Calculating urban area percentage\n\n// Calculating area of urban class\nvar urban = classified.select('classification').eq(1);\n\n// Calculate the pixel area in square kilometer for urban\nvar area_urban = urban.multiply(ee.Image.pixelArea()).divide(1000 * 1000);\n\n// Reducing the statistics for urban area in Delhi\nvar stat_urban = area_urban.reduceRegion({\n  reducer: ee.Reducer.sum(),\n  geometry: delhi,\n  scale: 100,\n  maxPixels: 1e10\n});\n\n// Get the sum of pixel values representing urban area\nvar area_urban_sum = ee.Number(stat_urban.get('classification'));\n\n// Calculate the pixel area in square kilometer for Delhi\nvar area_delhi = ee.Image.pixelArea().clip(delhi).divide(1000 * 1000);\n\n// Reducing the statistics for Delhi\nvar stat_delhi = area_delhi.reduceRegion({\n  reducer: ee.Reducer.sum(),\n  geometry: delhi,\n  scale: 100,\n  maxPixels: 1e10\n});\n\n// Get the sum of pixel values representing Delhi area\nvar area_delhi_sum = ee.Number(stat_delhi.get('area'));\n\n// Calculate the percentage of urban area\nvar percentage_urban_area = area_urban_sum.divide(area_delhi_sum).multiply(100);\n\n// Print the urban area in square kilometers\nprint('Urban Area (in sq.km):', area_urban_sum);\n\n// Print the total area of Delhi\nprint('Delhi Area (in sq.km):', area_delhi_sum);\n\n// Print the percentage of urban area\nprint('Percentage of urban area:', percentage_urban_area);\n\n\nExporting the Results:\nLastly, I exported the classified image and the confusion matrix results to Google Drive for further analysis and sharing with collaborators.\n\n// Code snippet 8: Exporting the classified image and confusion matrix to Google Drive\nExport.image.toDrive({\n  image: classified,\n  description: 'classified_image',\n  folder: 'GEE_Classification_Results',\n  scale: 10,\n  region: delhi\n});\n\nExport.table.toDrive({\n  collection: testAccuracy,\n  description: 'confusion_matrix',\n  folder: 'GEE_Classification_Results',\n  fileFormat: 'CSV'\n});"
  },
  {
    "objectID": "posts/delhi_lulc/index.html#results-and-conclusion",
    "href": "posts/delhi_lulc/index.html#results-and-conclusion",
    "title": "Satellite Image Clasification using Machine Learning",
    "section": "Results and Conclusion",
    "text": "Results and Conclusion\n\nThe land cover classification analysis using the basic Random Forest model achieved an overall accuracy of 87%, indicating the model’s effectiveness in accurately classifying land cover types in Delhi based on satellite imagery data.\nTo further improve the classification results, additional enhancements can be implemented, such as incorporating spectral indices like NDVI (Normalised Difference Vegetation Index) or NDBI (Normalised Difference Built-up Index) to provide additional information for distinguishing different land cover types.\nHyperparameter optimisation can be performed to fine-tune the Random Forest model, adjusting parameters such as the number of trees, tree depth, and feature subsampling, with the potential to achieve higher accuracy.\nThis project primarily focused on land cover classification in Delhi, but there is potential for extending the analysis to other Indian cities. Analysing the model’s performance in different urban environments would provide valuable insights into its generalisability and scalability.\nThe classification results suggest that approximately 78% of Delhi can be classified as urban, highlighting the significant urbanisation within the city.\nBy tracking the historical growth of urban areas in Delhi using satellite imagery, it is possible to gain a deeper understanding of urban expansion patterns over time.\n\nLink to Google Earth Engine script\nLink to original research paper"
  },
  {
    "objectID": "posts/d3s/index.html",
    "href": "posts/d3s/index.html",
    "title": "Data Science Slides",
    "section": "",
    "text": "During the spring of 2023, I had the incredible opportunity to contribute as a teaching fellow for an undergraduate course at Ashoka University. The course, titled “Data Science for Social Science,” was primarily aimed at students studying Political Science and Economics. As part of the teaching team, my responsibilities included leading weekly discussion sections, where I provided in-depth reviews of the data science methods covered in the main lectures.\nIn these discussion sections, my approach involved a combination of practical examples, live coding demonstrations, and addressing students’ queries and challenges with their coding tasks. Each week, I conducted six discussion sections, with an average of 15 students attending each session. Overall, the class consisted of approximately 90 students.\nTo showcase my contributions and provide insight into my teaching approach, I have compiled a selection of slides from my discussion sections. These slides capture the essence of the topics covered and the interactive learning environment fostered during the course.\nFeel free to explore the following slides, which offer a glimpse into my instructional techniques and the impact I had on the students’ understanding of data science in the context of social sciences.\nIntroduction to R and R Studio\nData Manipulation with dplyr\nMerging Data\nData Visualisation using ggplot2\nPredicting Housing Prices using Linear Regression"
  },
  {
    "objectID": "posts/gee-download/index.html",
    "href": "posts/gee-download/index.html",
    "title": "Satellite Image Download from Google Earth Engine using Python",
    "section": "",
    "text": "# import earth engine package and authenticate\nimport ee\ntry:\n    ee.Initialize()\nexcept:\n    ee.Authenticate()\n    ee.Initialize()"
  },
  {
    "objectID": "posts/gee-download/index.html#task-the-download",
    "href": "posts/gee-download/index.html#task-the-download",
    "title": "Satellite Image Download from Google Earth Engine using Python",
    "section": "Task the download",
    "text": "Task the download\n\n\ntask = ee.batch.Export.image.toDrive(**export_params)\ntask.start()\n\nThis will take a few mintues. You can check the progress at the task manager tab on GEE. Once it is finished, you can download the image from your google drive.\nHere is the link to the full notebook: github"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Satellite Image Download from Google Earth Engine using Python\n\n\n\nGEE\n\n\nRemote Sensing\n\n\nPython\n\n\n\n\n\n\n\nNajah\n\n\nJul 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSatellite Image Clasification using Machine Learning\n\n\n\nGEE\n\n\nRemote Sensing\n\n\nMachine Learning\n\n\njavascript\n\n\n\nEstimating the urbanisation in Delhi Using Google Earth Engine and Machine Learning\n\n\n\nNajah\n\n\nJun 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare Spectra App\n\n\n\nnews\n\n\ncode\n\n\napp\n\n\njavascript\n\n\n\nIntroducing the compare-spectra app\n\n\n\nNajah\n\n\nJun 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Viz gallery\n\n\n\nR\n\n\ncode\n\n\nViz\n\n\n\nA few of my data visualisations\n\n\n\nNajah\n\n\nMay 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSpatial Viz gallery\n\n\n\nViz\n\n\n\nA few of of my vector and raster maps\n\n\n\nNajah\n\n\nMay 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Slides\n\n\n\nR\n\n\ncode\n\n\nteaching\n\n\n\nMy teaching slides from the data science class\n\n\n\nNajah\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science works at CPR\n\n\n\nR\n\n\ncode\n\n\n\n\n\n\n\nNajah\n\n\nJan 31, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I’m Najah, a data scientist specialising in the intersection of remote sensing and machine learning. With a strong background in spatial data analysis and image processing, I thrive on extracting meaningful insights from satellite imagery. From assessing urban growth patterns to detecting burned areas, I’ve applied advanced algorithms to tackle diverse projects. As a Teaching Fellow and Teaching Assistant, I’ve had the privilege of guiding and mentoring students, helping them grasp complex data science concepts. I’m actively seeking new opportunities where I can apply my skills and expertise to make a tangible impact in the field."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Evaluating methods to map burned area at 30-meter resolution in forests and agricultural areas of Central India [2022]\nChandel, A., Sarwat, W., Najah, A., Dhanagare, S., & Agarwala, M. (2022, December 20). Evaluating methods to map burned area at 30-meter resolution in forests and agricultural areas of Central India. Frontiers in Forests and Global Change, 5. https://doi.org/10.3389/ffgc.2022.933807\nSabarimala, corruption, local body results: Why Kerala election is a tough call [2021]\nPublisher: India Today\nCo-Author: Rahul Verma \nMost BJP supporters want to take vaccines, Congress supporters not far behind [2021]\nPublisher: Hindustan Times - Live Mint\nCo-Authors: Rahul Verma and Ankita Barthwal\n\nMadhya Pradesh by-polls 2020: Advantage BJP over Congress [2020]\nPublisher: CNBC - TV18\n\nControlling India’s Coffee Market  [2018]\nPublication: Independent\nA business story - analysing how a coffee growing business turned into India’s largest coffee retailer -through the data driven journalism.\nCollaborators: Abhishek Mishra, Harish K Chandran\nIndia Doubling Petrol Pumps, Retailers Discontent [2018]\nPublication: Independent\nA data-driven story in the context of the Government's announcement to double the petrol pumps in India\nCollaborators: Abhishek Mishra, Harish K Chandran"
  }
]